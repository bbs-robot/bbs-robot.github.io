<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="Bidirectional Behavioral Sampling.">
  <meta name="keywords" content="BBS">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Bidirectional Behavioral Sampling: Understanding and Improving Action Chunking for Generative Behavioral Cloning</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());
    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.9.3/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/bbsicon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <style>
    .video-row {
      margin-bottom: 20px; /* Adjust the spacing between rows */
      padding: 10px; /* Adjust padding inside the shaded area */
      border-radius: 8px; /* Rounded corners for the border */
      box-shadow: 0px 4px 10px rgba(0, 0, 0, 0.20); /* Light shadow */
      background-color: #f9f9f9; /* Light background color */
    }
  </style>
  
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Bidirectional Behavioral Sampling: Understanding and Improving Action Chunking for Generative Behavioral Cloning</h1>
          <!-- Uncomment the following section to display author information
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://sites.google.com/view/yuejiangliu/home">Yuejiang Liu</a><sup>*</sup>,</span>
            <span class="author-block">
              <a href="https://jubayer-hamid.github.io/">Jubayer Ibn Hamid</a><sup>*</sup>,</span>
            <span class="author-block">
              <a href="https://anxie.github.io/">Annie Xie</a>,
            </span>
            <span class="author-block">
              <a href="https://www.yoonholee.com/">Yoonho Lee</a>,
            </span>
            <span class="author-block">
              <a href="https://www.maximiliandu.com/">Max Du</a>,
            </span>
            <span class="author-block">
              <a href="https://ai.stanford.edu/~cbfinn/">Chelsea Finn</a>.
            </span>
          </div>
          -->
          <!-- Uncomment the following line to display a logo
          <image src="./static/images/logo.jpg" style="width: 60%;"></image> 
          -->
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- Uncomment and replace the following sections to add links to your publication
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="content has-text-centered">
      <h1 class="title is-3">Real World Experiments: Dynamic Moving Objects</h1>  
    </div>
    <div class="video-row">
      <div class="columns is-centered is-multiline">
        <div class="column is-one-quarter">
          <div class="content has-text-centered">
            <h3 class="title is-6">Vanilla Open-Loop</h3>
            <video id="video2" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/Random_open_cup_stochastic.mov" type="video/mp4">
            </video>
            <p>Cannot react to stochasticity in environment - gripper closes before reaching the cup.</p>
          </div>
        </div>
        <div class="column is-one-quarter">
          <div class="content has-text-centered">
            <h3 class="title is-6">Vanilla Closed-Loop</h3>
            <video id="video3" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/Random_closed_cup_stochastic.mov" type="video/mp4">
            </video>
            <p>Reacts to stochasticity but cannot execute a long-term plan consistently resulting in jittery behavior.</p>
          </div>
        </div>
        <div class="column is-one-quarter">
          <div class="content has-text-centered">
            <h3 class="title is-6">EMA Closed-Loop</h3>
            <video id="video4" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/EMA_cup_stochastic.mov" type="video/mp4">
            </video>
            <p>Cannot react to environment stochasticity quickly enough.</p>
          </div>
        </div>
        <div class="column is-one-quarter">
          <div class="content has-text-centered">
            <h3 class="title is-6">BBS Closed-Loop</h3>
            <video id="video1" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/BID_cup_stochastic.mov" type="video/mp4">
            </video>
            <p>Reacts to environment stochasticity and carries out a consistent long-term plan.</p>
          </div>
        </div>
      </div>
    </div>
    <div class="content has-text-justified">
      <p>
        We use a pretrained diffusion policy and compare the performance of BBS with random sampling in open loop, random sampling in closed loop, and Exponential Moving Average (EMA) sampling. The first task is to pick up a moving cup whose initial position is fixed and place it on a nearby saucer. The cup is pulled with a string until both sides of the gripper touch the cup. BBS consistently outperforms the other methods achieving over 2x improvement in success rate.
      </p>
    </div>
    <div class="video-row">
      <div class="columns is-centered is-multiline">
        <div class="column is-one-quarter">
          <div class="content">
            <h3 class="title is-6">Vanilla Open-Loop (static)</h3>
            <video id="video5" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/vanilla_droptoy_statifc.mov" type="video/mp4">
            </video>
          </div>
        </div>
        <div class="column is-one-quarter">
          <div class="content">
            <h3 class="title is-6">BBS Closed-Loop (static)</h3>
            <video id="video6" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/BID_droptoy_static.mov" type="video/mp4">
            </video>
          </div>
        </div>
        <div class="column is-one-quarter">
          <div class="content">
            <h3 class="title is-6">Vanilla Open-Loop (dynamic)</h3>
            <video id="video7" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/vanilla_droptoy_stochastic.mov" type="video/mp4">
            </video>
          </div>
        </div>
        <div class="column is-one-quarter">
          <div class="content">
            <h3 class="title is-6">BBS Closed-Loop (dynamic)</h3>
            <video id="video8" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/BID_droptoy_stochastic.mov" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
    <div class="content has-text-justified">
      <p>
        In particular, we observe that open loop action decoding often struggles with precision even in the static setting. Our next task for the robot is to drop a toy into a plastic cup. In the dynamic setting, this cup is moved by hand as the robot carries out the task. In both static and dynamic settings, BBS achieves over 2x improvement in success rate compared to random sampling in open loop.
      </p>
    </div>
  </div>
  <div class="container is-max-desktop">
    <div class="content has-text-centered">
      <h1 class="title is-3">Simulation Experiments: Stochastic Action Noises</h1>
    </div>
    <div class="content has-text-justified">
      <p>
        In simulation, we evaluate BBS on the Push-T, RoboMimic, and 4-Object Franka Kitchen tasks. Below, we provide sample behaviors of the four methods on PushT and Franka Kitchen tasks in a stochastic environment.
      </p>
    </div>
    <div class="video-row">
      <div class="columns is-centered is-multiline">
        <div class="column is-one-quarter">
          <div class="content has-text-centered">
            <h3 class="title is-6">Vanilla Open-Loop</h3>
            <video id="video9" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/pusht_noisy_random_open.mov" type="video/mp4">
            </video>
            <p>Fails to react to the stochasticity in the environment.</p>
          </div>
        </div>
        <div class="column is-one-quarter">
          <div class="content has-text-centered">
            <h3 class="title is-6">Vanilla Closed-Loop</h3>
            <video id="video10" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/pusht_noisy_random_close.mp4" type="video/mp4">
            </video>
            <p>Reacts to stochasticity but lacks a long-term plan, causing jittery and inconsistent behavior.</p>
          </div>
        </div>
        <div class="column is-one-quarter">
          <div class="content has-text-centered">
            <h3 class="title is-6">EMA Closed-Loop</h3>
            <video id="video11" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/pusht_noisy_ema.mov" type="video/mp4">
            </video>
            <p>Fails to balance reactivity and long-term planning. Highly sensitive to decay rate.</p>
          </div>
        </div>
        <div class="column is-one-quarter">
          <div class="content has-text-centered">
            <h3 class="title is-6">BBS Closed-Loop</h3>
            <video id="video12" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/pusht_noisy_bbs.mov" type="video/mp4">
            </video>
            <p>Reacts to the stochasticity and carries out a consistent long-term plan.</p>
          </div>
        </div>
      </div>
    </div>
    <div class="video-row">
      <div class="columns is-centered is-multiline">
        <div class="column is-one-quarter">
          <div class="content">
            <h3 class="title is-6">Vanilla Open-Loop</h3>
            <video id="video13" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/random_open_noisy_franka.mp4" type="video/mp4">
            </video>
            <p>Fails to react to stochasticity causing failure modes like inability to grab objects.</p>
          </div>
        </div>
        <div class="column is-one-quarter">
          <div class="content">
            <h3 class="title is-6">Vanilla Closed-Loop</h3>
            <video id="video14" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/random_close_noisy_franka.mp4" type="video/mp4">
            </video>
            <p>Adapts to stochasticity but slow and jittery trajectories.</p>
          </div>
        </div>
        <div class="column is-one-quarter">
          <div class="content">
            <h3 class="title is-6">EMA Closed-Loop</h3>
            <video id="video15" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/ema_noisy_franka.mp4" type="video/mp4">
            </video>
            <p>Lacks long-term planning such as aiming for one control knob but then switching to another mid-way. Adapts to stochasticity but slow and jittery trajectories.</p>
          </div>
        </div>
        <div class="column is-one-quarter">
          <div class="content">
            <h3 class="title is-6">BBS Closed-Loop</h3>
            <video id="video16" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/bbs_noisy_franka.mp4" type="video/mp4">
            </video>
            <p>Adapts to the stochasticity and carries out a consistent long-term plan. BBS is also faster and smoother than EMA.</p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Predicting and executing a sequence of actions without intermediate replanning, known as action chunking, is increasingly used in robot learning from human demonstrations. However, its reported effects on the learned policy are inconsistent; some studies find it crucial for achieving strong results, while others observe decreased performance. In this paper, we first dissect how action chunking impacts the divergence between the learner and the demonstrator. We find that action chunking allows the model to capture the temporal dependencies in demonstrations (e.g., from high-level strategies and styles), but at the potential cost of accumulating uncertainty in dynamic environments (e.g., stochastic noise and unexpected changes), leading to compounding errors. To address this, we propose bidirectional behavioral sampling (BBS), a test-time inference algorithm that integrates action chunking with closed-loop operations. BBS samples a batch of multiple action chunks at each time step and explicitly searches for the optimal action based on two criteria: (i) backward decision coherence, which favors samples aligned with previous decisions, (ii) forward horizon contrast, which favors samples close to long-horizon plans and far from short-horizon ones. By coupling decisions within and across action chunks, BBS promotes strong temporal dependencies over multiple steps while maintaining high reactivity to unexpected state observations. Our experiment results show that BBS consistently outperforms conventional closed-loop operations, achieving an average of 26% relative improvements across seven manipulation tasks.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <figure class="image is-centered" style="margin-bottom: 0;">
          <img src="./static/images/teaser.png" alt="Analysis image">
        </figure>
      </div>
    </div>
  </div>
</section>

<section class="section" style="padding-top: 1rem;">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Analysis</h2>
        <h3 class="subtitle is-4">Why action chunking does not work in noisy/dynamic settings</h3>
        <div class="content has-text-justified">
          <p>
            In action chunking, the agent predicts the joint distribution of a sequence of actions conditioned on the context and then executes all or part of the sequence without replanning. In our analysis, we investigate the benefits and drawbacks of using a longer action chunk. Consider a shorter action chunk of length \( h \) and a longer one of length \( h + d \). The longer action chunk benefits from remembering more past states and suffers from having not observed the more recent states, as is illustrated below:
          </p>
      </div>
    </div>
  </div>
</section>


<section class="section" style="padding-top: 0;">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <figure class="image is-centered" style="margin-top: 0; margin-bottom: 0;">
          <img src="./static/images/Action Chunking.png" alt="Analysis gif" style="width: 90%; height: auto; display: block; margin: 0 auto;">
        </figure>
      </div>
    </div>
  </div>
</section>

<section class="section" style="padding-top: 1rem;">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          <p>
            Let the longer action chunk's distribution of \( a_t \) be \( \pi_{(c, h+d)}^t \) and that of the shorter action chunk be \( \pi_{(c, h)}^t \). Let the expert's distribution be \(\pi_{E}^t \).  
            The expected loss of the two agents with respect to the expert are related by the following inequality. 
            $$ \min_{\pi_{(c, h+d)}^t} \mathbb{E}_{G} \left[ \mathcal{L}(\pi_{(c, h+d)}^t - \pi_E^t) | C \right] \leq \min_{\pi_{(c, h)}^t} \mathbb{E}_{G} \left[\mathcal{L}(\pi_{(c, h)}^t - \pi_E^t) | C \right] - \alpha + \epsilon(1 - ( 1 - \delta)^{2d}). $$ 
            Here, \( \alpha \) represents the advantage from capturing more temporal dependencies in demos, showing a longer action chunk benefits from longer temporal coherence whilst suffering from \( \epsilon( 1 - (1 - \delta)^{2d} ) \) representing the loss due to dynamics uncertainty in the environment. 
          </p>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
        <h3 class="subtitle is-4">Bidirectional Behavioral Sampling</h3>
        <div class="content has-text-justified">
          <p>
            Our hypothesis suggests that while the probability of any pair of samples sharing the same latent strategy is low, the likelihood of finding a consistent pair from a large number of samples is significantly higher. This motivates us to solve the closed-loop action chunking problem by identifying the optimal action within a batch of plans at each time step, \( a^* = \arg \min_{a \in \mathcal{A}} \mathcal{L}_B(a) + \mathcal{L}_F(a) \) where  \( \mathcal{L}_B \) and \( \mathcal{L}_F \) are two criteria measuring the temporal dependency with respect to the backward decision and forward plan.
            To ensure temporal coherence, we  reference the action chunk from the previous time step, \( \{ \hat{a}_{t-1}, \cdots, \hat{a}_{t+h-1} \} \) and minimize the weighted sum of Euclidean distance across \( h - 1 \) overlapping steps: 
            $$ \mathcal{L}_B = \sum_{\tau=0}^{h-1} \rho^\tau \left\| a_{t+\tau} - {\hat a}_{t+\tau} \right\|_2. $$
            This encourages consistent latent strategies across time steps, while allowing for gradual adaptation to unforeseen environment dynamics. A robust policy should predict far enough to capture temporal dependencies in demonstrations. To ensure this, we compare each candidate plan with two reference sets: one from a long-horizon policy and the other from a short-horizon one. The forward objective minimizes the average distance to positive samples from long horizon policy, \( \mathcal{A}^+ \), and maximizes the average distance to negative samples from short horizon policy, \( \mathcal{A}^- \):
            $$ \mathcal{L}_F = \sum_{a^{+} \in \mathcal{A}^{+}} \sum_{\tau=0}^{h'} \left\| a_{t+\tau} - a^{+}_{t+\tau} \right\|_2 - \sum_{a^{-} \in \mathcal{A}^{-}} \sum_{\tau=0}^{h'} \left\| a_{t+\tau} - a^{-}_{t+\tau} \right\|_2, $$ where \( \mathcal{A}^{+} = \mathcal{A} \setminus \{a\} \) is the positive set predicted by the long-horizon policy \( \pi \), \( \mathcal{A}^{-} \) is the negative set predicted by the short-horizon one \( \pi' \), and \( h' \) is the short prediction horizon. We set \( h' = h / 4 \) to ensure a substantial horizon difference between the two policies.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" style="padding-top: 0;">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <figure class="image is-centered" style="margin-top: 0; margin-bottom: 0;">
          <img src="./static/images/search.png" alt="Analysis image" style="width: 40%; height: auto; display: block; margin: 0 auto;">
        </figure>
      </div>
    </div>
  </div>
</section>


<section class="section" style="padding-top: 1rem;">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Results</h2>
        <div class="content has-text-justified">
          <p>
            We evaluate BBS on the Push-T, RoboMimic, and 4-Object Franka Kitchen tasks. While existing inference methods offer some benefits for closed-loop operations, they either lack robustness or are highly sensitive to decay rate. BBS consistently achieves substantial gains across all tasks, surpassing the vanilla baseline by over 26% in relative improvements. 
          </p>
        <figure class="image is-centered" style="margin-bottom: 1rem;">
          <img src="./static/images/Simulation_results.png" alt="Comparison of methods">
        </figure>
        <div class="content has-text-justified">
          <p>
            In real world, we, first, consider a task where the robot is to deliver an object held in its gripper into a cup held by a human. This task mirrors
            real-world scenarios where robots interact with a dynamic environment, accommodating moving objects and agents.
          </p>
      </div>
      <figure class="image is-centered" style="margin-top: 1rem;">
        <img src="./static/images/Realworld_toy_results.png" alt="Real world task">
    </div>
    <div class="content has-text-justified">
      <p>
        In the second task, the robot is to pick up a moving cup and place it on a nearby saucer. BBS achieves over 2x improvement in success rate compared to all other methods in the stochastic
        setting while matching the performance of the best alternative in the static one.
      </p>
  </div>
  <figure class="image" style="margin-top: 1rem; display: flex; justify-content: center;">
    <img src="./static/images/Realworld_cup_results.png" alt="Real world task" style="width: 75%;">
  </figure>
</section>




<!-- 
<section class="section">
  <div class="container is-max-desktop">
    <div class="content has-text-centered">
      <h1 class="title is-2">Simulation Benchmarks</h1>
    </div>
    <div class="content has-text-justified">
      <p>
        We evaluate BBS on the Push-T, RoboMimic, and 4-Object Franka Kitchen tasks. While existing inference methods offer some benefits for closed-loop operations, they lack robustness. 
        BBS consistently achieves substantial gains across all tasks, surpassing the vanilla baseline by over 26% in relative improvements. We provide demonstrations of four of the methods on 
        the PushT task in a stochastic environment. 
      </p>
    </div>
    <div class="columns is-centered is-multiline">
      <div class="column is-one-quarter">
        <div class="content">
          <h3 class="title is-5">Random (open loop)</h3>
          <video id="video2" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/pusht_noisy_random_open.mov" type="video/mp4">
          </video>
          <p>
            Fails to adapt to the stochasticity in the environment. 
          </p>
        </div>
      </div>
      <div class="column is-one-quarter">
        <div class="content">
          <h3 class="title is-5">Random (closed loop)</h3>
          <video id="video3" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/pusht_noisy_random_close.mp4" type="video/mp4">
          </video>
          <p>
            Adapts to stochasticity but lacks a long-term plan. 
          </p>
        </div>
      </div>
      <div class="column is-one-quarter">
        <div class="content">
          <h3 class="title is-5">EMA (closed loop)</h3>
          <video id="video4" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/pusht_noisy_ema.mov" type="video/mp4">
          </video>
          <p>
            Fails to balance adaptability and long-term planning. Highly sensitive to decay rate. 
          </p>
        </div>
      </div>
      <div class="column is-one-quarter">
        <div class="content">
          <h3 class="title is-5">BBS</h3>
          <video id="video1" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/pusht_noisy_bbs.mov" type="video/mp4">
          </video>
          <p>
            Adapts to the stochasticity and carries out a consistent long-term plan.
          </p>
        </div>
      </div>
    </div>
    <div class="content has-text-justified">
      <p>
        Next, we demonstate the performance of the four methods on the Franka Kitchen.
      </p>
    </div>
    <div class="columns is-centered is-multiline">
      <div class="column is-one-quarter">
        <div class="content">
          <h3 class="title is-5">Random (open loop)</h3>
          <video id="video2" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/random_open_noisy_franka.mp4" type="video/mp4">
          </video>
          <p>
            Fails due to inability to adapt to stochasticity. 
          </p>
        </div>
      </div>
      <div class="column is-one-quarter">
        <div class="content">
          <h3 class="title is-5">Random (closed loop)</h3>
          <video id="video3" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/random_close_noisy_franka.mp4" type="video/mp4">
          </video>
          <p>
            Adapts to stochasticity but slow and jittery trajectories. 
          </p>
        </div>
      </div>
      <div class="column is-one-quarter">
        <div class="content">
          <h3 class="title is-5">EMA (closed loop)</h3>
          <video id="video4" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/ema_noisy_franka.mp4" type="video/mp4">
          </video>
          <p>
            Lacks long-term planning such as aiming for one control knob but then switching to another. Adapts to stochasticity but slow and jittery trajectories.  
          </p>
        </div>
      </div>
      <div class="column is-one-quarter">
        <div class="content">
          <h3 class="title is-5">BBS</h3>
          <video id="video1" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/bbs_noisy_franka.mp4" type="video/mp4">
          </video>
          <p>
            Adapts to the stochasticity and carries out a consistent long-term plan. BBS is also faster and smoother than EMA.
          </p>
        </div>
      </div>
  </div>
</section> -->







<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{liu2024bidirectional,
  author    = {Liu, Yuejiang and Hamid, Jubayer Ibn and Xie, Annie and Lee, Yoonho and Du, Max and Finn, Chelsea},
  title     = {Bidirectional Behavioral Sampling: Understanding and Improving Action Chunking for Generative Behavioral Cloning},
  journal   = {arXiv},
  year      = {2024},
}</code></pre>
  </div>
</section> -->


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <p>Page template borrowed from <a href="https://nerfies.github.io/"><span class="dnerf">Nerfies</span></a> and <a href="https://mobile-aloha.github.io/"><span class="dnerf">Mobile ALOHA</span></a>.</p>
    </div>
  </div>
</footer>

</body>
</html>