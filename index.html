<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Bidirectional Behavioral Sampling.">
  <meta name="keywords" content="BBS">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Bidirectional Behavioral Sampling: Understanding and Improving Action Chunking for Generative Behavioral Cloning.</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.9.3/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Bidirectional Behavioral Sampling: Understanding and Improving Action Chunking for Generative Behavioral Cloning.</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://sites.google.com/view/yuejiangliu/home">Yuejiang Liu</a><sup>*</sup>,</span>
            <span class="author-block">
              <a href="https://jubayer-hamid.github.io/">Jubayer Ibn Hamid</a><sup>*</sup>,</span>
            <span class="author-block">
              <a href="https://anxie.github.io/">Annie Xie</a>,
            </span>
            <span class="author-block">
              <a href="https://www.yoonholee.com/">Yoonho Lee</a>,
            </span>
            <span class="author-block">
              <a href="https://www.maximiliandu.com/">Max Du</a>,
            </span>
            <span class="author-block">
              <a href="https://ai.stanford.edu/~cbfinn/">Chelsea Finn</a>.
            </span>
          </div>
          <image src="./static/images/logo.jpg" style="width: 60%;"></image>
          <div>
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="https://www.w3schools.com/html/mov_bbb.mp4" type="video/mp4">
        Placeholder video. 
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">BBS</span> teaser free-viewpoint portraits.
      </h2>
    </div>
  </div>
</section>


<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Predicting and executing a sequence of actions without intermediate replanning, known as action chunking, is increasingly used in robot learning from human demonstrations. However, its reported effects on the learned policy are inconsistent; some studies find it crucial for achieving strong results, while others observe decreased performance. In this paper, we first dissect how action chunking impacts the divergence between the learner and the demonstrator. We find that action chunking allows the model to capture the temporal dependencies in demonstrations (e.g., from high-level strategies and styles), but at the potential cost of accumulating uncertainty in dynamic environments (e.g., stochastic noise and unexpected changes), leading to compounding errors. To address this, we propose bidirectional behavioral sampling (BBS), a test-time inference algorithm that integrates action chunking with closed-loop operations. BBS samples a batch of multiple action chunks at each time step and explicitly searches for the optimal action based on two criteria: (i) backward decision coherence, which favors samples aligned with previous decisions, (ii) forward horizon contrast, which favors samples close to long-horizon plans and far from short-horizon ones. By coupling decisions within and across action chunks, BBS promotes strong temporal dependencies over multiple steps while maintaining high reactivity to unexpected state observations. Our experiment results show that BBS consistently outperforms conventional closed-loop operations, achieving an average of 26% relative improvements across seven manipulation tasks.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>

<!-- Analysis section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <figure class="image is-centered">
          <img src="./static/images/teaser.png" alt="Analysis image">
        </figure>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Analysis</h2>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          <p>
            In action chunking, the agent predicts the joint distribution of a sequence of actions conditioned on the context and then executes all or part of the sequence without replanning. In our analysis, we investigate the benefits and drawbacks of using a longer action chunk. Consider a shorter action chunk of length \( h \) and a longer one of length \( h + d \). The longer action chunk benefits from remembering more past states and suffers from having not observed 
            the more recent states, as is illustrated below:
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <figure class="image is-centered">
          <img src="./static/images/Action Chunking.png" alt="Analysis gif" style="width: 90%; height: auto; display: block; margin: 0 auto;">
        </figure>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          <p>
            Let the longer action chunk's distribution of \( a_t \) be \( \pi_{(c, h+d)}^t \) and that of the shorter action chunk be \( \pi_{(c, h)}^t \). Let the expert's distribution be \(\pi_{E}^t \).  
            The expected loss of the two agents with respect to the expert are related by the following inequality. 
            $$ \min_{\pi_{(c, h+d)}^t} \mathbb{E}_{G} \left[ \mathcal{L}(\pi_{(c, h+d)}^t - \pi_E^t) | C \right] \leq \min_{\pi_{(c, h)}^t} \mathbb{E}_{G} \left[\mathcal{L}(\pi_{(c, h)}^t - \pi_E^t) | C \right] - \alpha + \epsilon(1 - ( 1 - \delta)^{2d}). $$ 
            Here, \( \alpha \) represents the advantage from capturing more temporal dependencies in demos, showing a longer action chunk benefits from longer temporal coherence whilst suffering from \( \epsilon( 1 - (1 - \delta)^{2d} ) \) representing the loss due to dynamics uncertainty in the environment. 
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- <section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <figure class="image is-centered">
          <img src="./static/images/PRILearners.jpg" alt="Analysis image" style="width: 40%; height: auto; display: block; margin: 0 auto;">
        </figure>
        <h2 class="subtitle has-text-centered">
          Illustrating the two action chunks in our analysis. The green and blue cells represent the context and action chunk, respectively.
        </h2>
      </div>
    </div>
  </div>
</section> -->


<!-- Method section -->
<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
        <div class="content has-text-justified">
          <p>
            Our hypothesis suggests that while the probability of any pair of samples sharing the same latent strategy is low, the likelihood of finding a consistent pair from a large number of samples is significantly higher. This motivates us to solve the closed-loop action chunking problem by identifying the optimal action within a batch of plans at each time step, \( a^* = \arg \min_{a \in \mathcal{A}} \mathcal{L}_B(a) + \mathcal{L}_F(a) \) where  \( \mathcal{L}_B \) and \( \mathcal{L}_F \) are two criteria measuring the temporal dependency with respect to the backward decision and forward plan.
            To ensure temporal coherence, we  reference the action chunk from the previous time step, \( \{ \hat{a}_{t-1}, \cdots, \hat{a}_{t+h-1} \} \) and minimize the weighted sum of Euclidean distance across \( h - 1 \) overlapping steps: 
            $$ \mathcal{L}_B = \sum_{\tau=0}^{h-1} \rho^\tau \left\| a_{t+\tau} - {\hat a}_{t+\tau} \right\|_2. $$
            This encourages consistent latent strategies across time steps, while allowing for gradual adaptation to unforeseen environment dynamics. A robust policy should predict far enough to capture temporal dependencies in demonstrations. To ensure this, we compare each candidate plan with two reference sets: one from a long-horizon policy and the other from a short-horizon one. The forward objective minimizes the average distance to positive samples from long horizon policy, \( \mathcal{A}^+ \), and maximizes the average distance to negative samples from short horizon policy, \( \mathcal{A}^- \):
            $$ \mathcal{L}_F = \sum_{a^{+} \in \mathcal{A}^{+}} \sum_{\tau=0}^{h'} \left\| a_{t+\tau} - a^{+}_{t+\tau} \right\|_2 - \sum_{a^{-} \in \mathcal{A}^{-}} \sum_{\tau=0}^{h'} \left\| a_{t+\tau} - a^{-}_{t+\tau} \right\|_2, $$ where \( \mathcal{A}^{+} = \mathcal{A} \setminus \{a\} \) is the positive set predicted by the long-horizon policy \( \pi \), \( \mathcal{A}^{-} \) is the negative set predicted by the short-horizon one \( \pi' \), and \( h' \) is the short prediction horizon. We set \( h' = h / 4 \) to ensure a substantial horizon difference between the two policies.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <figure class="image is-centered">
          <img src="./static/images/search.png" alt="Analysis image" style="width: 40%; height: auto; display: block; margin: 0 auto;">
        </figure>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <!-- Visual Effects. -->
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Simulations 1</h2>
          <p>
            <i>BBS</i> simulations.
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/dollyzoom-stacked.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ Visual Effects. -->

      <!-- Matting. -->
      <div class="column">
        <h2 class="title is-3">Simulation 2</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              <i>BBS</i> simulations.
            </p>
            <video id="matting-video" controls playsinline height="100%">
              <source src="./static/videos/matting.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
    </div>
    <!--/ Matting. -->

    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3" style="text-align: center;">Real World Experiments</h2>

        <!-- Re-rendering. -->
        <h3 class="title is-4" style="text-align: center;">Navigation + Manipulation</h3>
        <div class="content has-text-justified" style="text-align: center;">
          <p>
            Using <span class="dnerf">Nerfies</span>, you can re-render a video from a novel
            viewpoint such as a stabilized camera by playing back the training deformations.
          </p>
        </div>
        <div class="content has-text-centered" style="text-align: center;">
          <video id="replay-video"
                controls
                muted
                preload
                playsinline
                width="75%">
            <source src="./static/videos/replay.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
    <!--/ Animation. -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{liu2024bidirectional,
  author    = {Liu, Yuejiang and Hamid, Jubayer I. and Xie, Annie and Lee, Yoonho and Du, Max and Finn, Chelsea},
  title     = {Bidirectional Behavioral Sampling: Understanding and Improving Action Chunking for Generative Behavioral Cloning},
  journal   = {arXiv},
  year      = {2024},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <p>Page template borrowed from <a href="https://nerfies.github.io/"><span class="dnerf">Nerfies</span></a> and <a href="https://mobile-aloha.github.io/"><span class="dnerf">Mobile ALOHA</span></a>.</p>
    </div>
  </div>
</footer>

</body>
</html>
